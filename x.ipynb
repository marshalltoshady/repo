{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "This a notebook for COMP5349 Cloud Computing Assignment 2, implementing Spark Framework for data analyiss of online review data set released by Amazon on US sites. It provide various analytic phases to evaluate the data and calculate summary statistics, removing unwanted and meanning less data and finally performing some similarity analysis between review sentences.\n\nThe original data include product review information of Video DVD products from Amazon between 1995 and 2015. Each row reprenst one review given by one custoer on one prodcut and containing 15 columns of informaiton. This work load has only applied anaylisis based 5 columns of informaiton: customer_id, review_id, product_id, star_rating, review_body, while the additional information are striped out.\n\nThis notebook is designed to run on AWS EMR and obtain data from S3, after it's been downloaed into the bucket."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from pyspark.sql import SparkSession,dataframe\nfrom pyspark.sql.types import StructType,StructField,StringType,IntegerType,FloatType\nfrom nltk.tokenize import sent_tokenize\nimport pyspark.sql.functions as fc\nimport numpy as np \nimport tensorflow as tf\nimport tensorflow_hub as hub \nimport scipy as sp ", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "58b0609e062e4c69a229cdf97410798a"}}, "metadata": {}}, {"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1558506225954_0006</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-73-75.ec2.internal:20888/proxy/application_1558506225954_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-68-153.ec2.internal:8042/node/containerlogs/container_1558506225954_0006_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "data = \"s3://comp5349-ass2-wdai9162/amazon_reviews_us_Video_DVD_v1_00.tsv.gz\"\nschema = StructType([\n    StructField(\"marketplace\", StringType(), True),\n    StructField(\"customer_id\", StringType(), True),\n    StructField(\"review_id\", StringType(), True),\n    StructField(\"product_id\", StringType(), True),\n    StructField(\"product_parent\", IntegerType(), True),\n    StructField(\"product_title\",StringType(),True),\n    StructField(\"product_category\",StringType(),True),\n    StructField(\"star_rating\",IntegerType(),True),\n    StructField(\"helpful_votes\",IntegerType(),True),\n    StructField(\"total_votes\",IntegerType(),True),\n    StructField(\"vine\",StringType(),True),\n    StructField(\"verified_purchase\",StringType(),True),\n    StructField(\"review_headline\",StringType(),True),\n    StructField(\"review_body\",StringType(),False),\n    StructField(\"review_date\",StringType(),True)])\n\n\n#\"review_body\" column has been set to not allowing for N/A type, due to possible error during tokenization ", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c64b3ad13eeb4e00be6a8254734b1694"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#read the data according to the defined schema\nreviews = spark.read.csv(data,sep='\\t',header=True, schema=schema)\n\n#remove unrelated data column, keeping only customer_id, review_id, product_id, star_rating, review_body\n#cache it to the default storage level \nclean_reviews = reviews.drop(\"marketplace\") \\\n.drop(\"product_parent\") \\\n.drop(\"product_title\") \\\n.drop(\"product_category\") \\\n.drop(\"helpful_votes\") \\\n.drop(\"total_votes\") \\\n.drop(\"vine\") \\\n.drop(\"verified_purchase\") \\\n.drop(\"review_headline\") \\\n.drop(\"review_date\") \\\n.repartition(3) \\\n.cache()\n\n#.sample(True,0.5) \\\n\n#clean_reviews.count() #94s-1%data  ", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4f1ee1aa872f43b5909d3f3f85be442b"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Stage 1.1 \n\n#total number of reviews - approx 66.0s,73.0s -> 43s (1+3 m4.xlarge)\ntotal = clean_reviews.rdd.count()\nprint (\"the total number of reviews is %d\" %(total))\n\nspark.conf.set(\"spark.sql.shuffle.partitions\", 20)\n\n#the number of unique users - approx 84.0s , 76.0s -> 64s (1+3 m4.xlarge)\nuniq_usr = clean_reviews.dropDuplicates([\"customer_id\"]).count()\nprint (\"the number of unique users is %d\" %(uniq_usr))\n\n#the number of unique products - approx 72.1s -> 67s (1+3 m4.xlarge)\nuniq_prdct = clean_reviews.dropDuplicates([\"product_id\"]).count()\nprint (\"the number of unique products is %d\" %(uniq_prdct))", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "7ae77dd23a1d4247aa37fae966b53032"}}, "metadata": {}}, {"output_type": "stream", "text": "the total number of reviews is 5069140\nthe number of unique users is 2075970\nthe number of unique products is 297919\n----------------------------------------\nException happened during processing of request from ('127.0.0.1', 52936)\nTraceback (most recent call last):\n  File \"/usr/lib64/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n    self.process_request(request, client_address)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 351, in process_request\n    self.finish_request(request, client_address)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 364, in finish_request\n    self.RequestHandlerClass(request, client_address, self)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 724, in __init__\n    self.handle()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 266, in handle\n    poll(authenticate_and_accum_updates)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 241, in poll\n    if func():\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 254, in authenticate_and_accum_updates\n    received_token = self.rfile.read(len(auth_token))\nTypeError: object of type 'NoneType' has no len()\n----------------------------------------", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Stage 1.2 \nspark.conf.set(\"spark.sql.shuffle.partitions\", 20)\n\n#the largest number of reviews published by a single user - approx 106.0s \nmax_reviews_byUsr = clean_reviews.groupBy(\"customer_id\").count().cache().agg({\"count\": \"max\"}).collect()\nprint (\"the largest number of reviews published by a single user is %d\" %(max_reviews_byUsr[0]))\n\n#the top 10 users ranked by the number of reviews they publish - approx 83.0s \nsorted_list_user = clean_reviews.groupBy(\"customer_id\").count().orderBy(\"count\",ascending=[0]).show(10)\n \n#the median number of reviews published by a user - approx 85.0s \ndef calc_median(column):\n    try:\n        median = np.median(column) \n        return round(float(median),2)\n    except Exception:\n        return \"input error\" #return nothing if given value is wrong \n\nmedian_finder = fc.udf(calc_median,FloatType()) #define function for spark datafram \n\nreview_list = clean_reviews.groupBy(\"customer_id\").count().agg(fc.collect_list(\"count\").alias(\"counts\"))\nreview_list = review_list.withColumn(\"median\",median_finder(\"counts\")).cache()\nreview_list.show()\n\n#store median for stage 2 use \nmedian_reviews_byUsr = int(review_list.select(\"median\").collect()[0][0])", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3321ddeb9f57404a9940305df70c7c56"}}, "metadata": {}}, {"output_type": "stream", "text": "the largest number of reviews published by a single user is 3582\n+-----------+-----+\n|customer_id|count|\n+-----------+-----+\n|   43430756| 3582|\n|   18116317| 2987|\n|   52287429| 2747|\n|   52496677| 2650|\n|   51110953| 2624|\n|   19792742| 2495|\n|   20018062| 2492|\n|   50068216| 2379|\n|   14539589| 2269|\n|   50881246| 2104|\n+-----------+-----+\nonly showing top 10 rows\n\n+--------------------+------+\n|              counts|median|\n+--------------------+------+\n|[24, 9, 107, 3, 1...|   1.0|\n+--------------------+------+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Stage 1.3 \nspark.conf.set(\"spark.sql.shuffle.partitions\", 20)\n\n#the largest number of reviews written for a single product - approx 105.0s \nmax_reviews_Product = clean_reviews.groupBy(\"product_id\").count().agg({\"count\": \"max\"}).collect()\nprint (\"the largest number of reviews written for a single product %d\" %(max_reviews_Product[0]))\nmax_review = max_reviews_Product[0]\n\n#the top 10 products ranked by the number of reviews they have - approx 84.0s \nsorted_products = clean_reviews.groupBy(\"product_id\").count().orderBy(\"count\",ascending=[0])\nsorted_products.show(10)\n\n#the median number of reviews a product has\nproduct_list = clean_reviews.groupBy(\"product_id\").count().agg(fc.collect_list(\"count\").alias(\"counts\"))\nproduct_list = product_list.withColumn(\"median\",median_finder(\"counts\"))\nproduct_list.show()\n#store median for stage 2 use \nmedian_reviews_byPro = int(product_list.select(\"median\").collect()[0][0])", "execution_count": 6, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b5be4fc5aa924cafb6c9fcc497fd23f4"}}, "metadata": {}}, {"output_type": "stream", "text": "the largest number of reviews written for a single product 4969\n+----------+-----+\n|product_id|count|\n+----------+-----+\n|B00127RAJY| 4969|\n|B0000AQS0F| 4967|\n|B00G5G7K7O| 4439|\n|B0002IQJ96| 4409|\n|B00G5G7EXY| 4207|\n|B003ZSJ212| 3641|\n|B000X9FLKM| 3414|\n|B000K8LV1O| 2989|\n|B00N1JQ2UO| 2476|\n|B00AMR5LZA| 2253|\n+----------+-----+\nonly showing top 10 rows\n\n+--------------------+------+\n|              counts|median|\n+--------------------+------+\n|[162, 109, 57, 7,...|   3.0|\n+--------------------+------+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Stage 2.1 FILTER ONE - reviews with less than two sentences in the review body.\ndef custom_tokenize(text):\n    if not text:\n        text = ''\n    return sent_tokenize(text)\n\n#reviews with less than two sentences in the review_body - covert to RDD \nclean_reviews_filter_1 = clean_reviews.rdd.filter(lambda row:(len(custom_tokenize(row.review_body)))>=2).cache()\nclean_reviews_filter_1.count()", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ccf6be1b7a7541848ecce36cefdbf00a"}}, "metadata": {}}, {"output_type": "stream", "text": "4016567", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Stage 2.2 FILTER TWO - reviews published by users with less than median number of reviews published\nfrom pyspark.sql import Window\nwindow = Window.partitionBy(\"customer_id\")\nclean_reviews_filter_2 = clean_reviews_filter_1.toDF().withColumn(colName = \"review_count\",col=fc.count(\"review_id\").over(window)) \\\n.filter(\"review_count > %s\" % median_reviews_byUsr).drop(\"review_count\").cache()\n\nclean_reviews_filter_2.count()", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "16a0a139bd6142e29c50eab524587b37"}}, "metadata": {}}, {"output_type": "stream", "text": "2784806", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Stage 2.3 FILTER THREE - reviews from products with less than median number of reviews received\nwindow = Window.partitionBy(\"product_id\")\nclean_reviews_filter_3 = clean_reviews_filter_2.withColumn(colName = \"review_count_p\",col=fc.count(\"review_id\").over(window)) \\\n.filter(\"review_count_p > %s\" % median_reviews_byPro).drop(\"review_count_p\").cache()\n\nclean_reviews_filter_3.count()", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5da48a6408d148259bc09bdf647a300d"}}, "metadata": {}}, {"output_type": "stream", "text": "2573240", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Stage 2.4 top 10 users ranked by median number of sentences in the reviews they provided  \nclean_reviews_filter_3.rdd.map(lambda row:(row.customer_id,len(sent_tokenize(row.review_body)))). \\\ngroupByKey().mapValues(sum).\\\nsortBy(lambda row:row[1],0).top(10,key=lambda row:row[1])\n", "execution_count": 10, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "072ae7916663432cae16ce7b64e402a8"}}, "metadata": {}}, {"output_type": "stream", "text": "[('12797924', 65317), ('19792742', 59591), ('51720265', 58834), ('49770892', 50601), ('50068216', 47156), ('38002140', 43163), ('50881246', 40991), ('50913245', 38952), ('52012289', 37770), ('52048190', 37042)]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Stage 2.5 top 10 products ranked by median number of sentences in the reviews they have received \nclean_reviews_filter_3.rdd.map(lambda row:(row.product_id,len(sent_tokenize(row.review_body)))). \\\ngroupByKey().mapValues(sum).\\\nsortBy(lambda row:row[1],0).top(10,key=lambda row:row[1])\n", "execution_count": 25, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "30ed9b959c514e56bec5864dee5e17bc"}}, "metadata": {}}, {"output_type": "stream", "text": "[('B0000AQS0F', 19756), ('B00127RAJY', 13981), ('B00003CXCT', 13846), ('B003ZSJ212', 13688), ('B00006HBUJ', 12621), ('B00003CX5P', 12509), ('B00005JMJ4', 11364), ('B00005JLXH', 9224), ('B00028HBKM', 8850), ('B008JFUPK8', 8772)]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#stage 3 \n\n#pick the most popular prodcut by review number according to result calculated from stage 1.3 \npop_product_1st = sorted_products.select(\"product_id\").collect()[0][0]\nstage3_data = clean_reviews_filter_3.filter(clean_reviews_filter_3.product_id == pop_product_1st).cache()\n\npositive_class = stage3_data.filter(stage3_data.star_rating >= 4)\npositive_review = positive_class.select(\"review_body\").rdd.flatMap(lambda x: x).collect()\n\nnegative_class = stage3_data.filter(stage3_data.star_rating <= 2)\nnegative_review = negative_class.select(\"review_body\").rdd.flatMap(lambda x: x).collect()\n\nprint (\"positive reviews of product %s = %d\"%(pop_product_1st,len(positive_review)))\nprint (\"negative reviews of product %s = %d\"%(pop_product_1st,len(negative_review)))", "execution_count": 12, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "bd42cd2469374340b5383170dedebe35"}}, "metadata": {}}, {"output_type": "stream", "text": "positive reviews of product B00127RAJY = 1521\nnegative reviews of product B00127RAJY = 73", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Utilzing Google pre-trained universal word embedding model to parse sentences to vectors \n\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" \nembed = hub.Module(module_url) \n\n#sentence segamentation for positive lists \npositive_review_sent = [] \n\nfor i in range (len(positive_review)):\n    positive_review_sent.append(sent_tokenize(positive_review[i]))\n    \nf_positive_sent = [y for x in positive_review_sent for y in x] #flat the list \n\n#sentence segamentation for negative lists \nnegative_review_list = [] \nfor i in range (len(negative_review)):\n    negative_review_list.append(sent_tokenize(negative_review[i]))\n\nf_negative_sent = [y for x in negative_review_list for y in x] #flat the list ", "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "502296f599c7457da2ee382dde564274"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Use Google Pre-trained universal sentence encoder to encode each sentence to 512 dimension vector \nwith tf.Session() as session:\n    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n    sentence_embeddings_pos = session.run(embed(f_positive_sent))\n    sentence_embeddings_neg = session.run(embed(f_negative_sent))", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "94d38ee3e9c34c12a9c785006337b6b7"}}, "metadata": {}}, {"output_type": "stream", "text": "[None, None]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#5.2 Intra-Class Similarity, 0 = similar, 2 = different/opposite \nfrom scipy.spatial.distance import pdist,cdist\n\n#calculate pairwise distances between observations in n-dimensional space.\ndist_matrix_positive = pdist(sentence_embeddings_pos,\"cosine\")\ndist_matrix_negative = pdist(sentence_embeddings_neg,\"cosine\")\ndist_matrix_between = cdist(sentence_embeddings_pos,sentence_embeddings_neg,\"cosine\")\n\n\naverage_dist_positive = np.mean(dist_matrix_positive)\naverage_dist_negative = np.mean(dist_matrix_negative)\n\nprint (average_dist_positive)\nprint (average_dist_negative)", "execution_count": 15, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "05e527fc2a8f4b52a827578f09cef162"}}, "metadata": {}}, {"output_type": "stream", "text": "0.6830594701765739\n0.7267939128184078", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "np.mean(np.mean(dist_matrix_between,axis=1))", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "995a674f88db4783a1eaf43eb82d2e04"}}, "metadata": {}}, {"output_type": "stream", "text": "0.7128082123923787", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Stage Four 6.1 \n#prepare date by writing out to disk and read back in as Dataframe\nfrom pyspark.mllib.feature import Word2Vec\n\nimport re \n\n#prepare data for model training and removing unnecessary regs \npositive_class_test = positive_class.select(\"review_body\").rdd.map(lambda x: sent_tokenize(re.sub(r'&#[0-9]+;',' ',\n                                                                          re.sub(r'<br />',' ', x[0]))))\n\n                                                                          \nnegative_class_test = negative_class.select(\"review_body\").rdd.map(lambda x: sent_tokenize(re.sub(r'&#[0-9]+;',' ',\n                                                                          re.sub(r'<br />',' ', x[0]))))\n\n\nmodel_Pos = Word2Vec().setVectorSize(100).setMinCount(1).setSeed(42).fit(positive_class_test)\nmodel_Neg = Word2Vec().setVectorSize(100).setMinCount(1).setSeed(42).fit(negative_class_test)\n\n\n", "execution_count": 27, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5f92610d44294824864c5f0479f81d53"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "a = model_Pos.getVectors()\n\nprint (len(a))\n", "execution_count": 28, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d2add35d0a5143a4ad0df9d068a71e98"}}, "metadata": {}}, {"output_type": "stream", "text": "12688", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "b = model_Neg.getVectors()\n\nprint (len(b))", "execution_count": 29, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "8cae498aa53740868a15b347236dba3f"}}, "metadata": {}}, {"output_type": "stream", "text": "646", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "pos_list=[]\n\nfor x in a:\n    pos_list.append(a[x])\n    \n\nc=np.array(pos_list)\nc.shape", "execution_count": 30, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "faeb74ab875349aaaa33a5fa815b01ea"}}, "metadata": {}}, {"output_type": "stream", "text": "(12688, 100)", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "neg_list=[]\n\nfor x in b:\n    neg_list.append(b[x])\n    \nd=np.array(neg_list)\nd.shape", "execution_count": 31, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e0a69ffc7efc428ba8c4693806d1c6f3"}}, "metadata": {}}, {"output_type": "stream", "text": "(646, 100)", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print (pdist(c),\"cosine\") \nprint (np.mean(pdist(c)))", "execution_count": 32, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "28fbb98113f64b09b02afde9cee5341c"}}, "metadata": {}}, {"output_type": "stream", "text": "[0.05080126 0.0471834  0.04869655 ... 0.04567042 0.03953254 0.04673391] cosine\n0.044226288920317776", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print (pdist(d),\"cosine\") \nprint (np.mean(pdist(d)))", "execution_count": 33, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b5950b855d1a4d1b8b2f26c4993fdd93"}}, "metadata": {}}, {"output_type": "stream", "text": "[0.04298129 0.046965   0.03761173 ... 0.03929249 0.03910964 0.04232494] cosine\n0.04080857673629429", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print (cdist(c,d),\"cosine\")\n", "execution_count": 34, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d54e5260602345f8affba96ed1ce2175"}}, "metadata": {}}, {"output_type": "stream", "text": "[[0.05180001 0.05176109 0.05240793 ... 0.05365713 0.05143519 0.04981803]\n [0.04169833 0.04355046 0.0426913  ... 0.04142708 0.04340602 0.04390789]\n [0.04208087 0.03955149 0.04095635 ... 0.03963504 0.04361656 0.04501934]\n ...\n [0.0410593  0.04164201 0.04258026 ... 0.04067823 0.04187385 0.0426368 ]\n [0.04423372 0.04225778 0.0415093  ... 0.03996423 0.04847304 0.04220427]\n [0.04311021 0.04463898 0.03813571 ... 0.03814442 0.04374516 0.0418509 ]] cosine", "name": "stdout"}]}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}